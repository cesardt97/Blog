{
  "hash": "21bd9d034a8bf8fcf3632849d7299a27",
  "result": {
    "markdown": "---\ntitle: \"Tryout code\"\nauthor: \"César Díaz Tavera\"\ndate: \"2022-08-30\"\ncategories: [Econometría financiera, GARCH, Análisis de volatilidad, ]\nimage: \"financial-econometrics.jpg\"\n---\n\n\n## **Introducción**\n\nLa teoría moderna del portafolio fue introducida por el premio Nobel de economía Henry Markowitz en 1952 con su ensayo 'Portafolio Selection' publicado en el *Journal of Finance*. Fundamentalmente, esta teoría asume que el intercambio entre rentabilidad y riesgo[^1] de los activos financieros no se deben de considerar de manera individual (el cual era el consejo consensuado en la época), sino que se debe de considerar esa relación de intercambio desde el conjunto de la cartera. Es decir, los inversionistas deberían enfocarse en seleccionar carteras, en lugar de formar sus portafolios a partir de la selección individual de activos atractivos. De todo el universo de portafolios posibles, algunos equilibrarán de manera óptima el riesgo y la recompensa. Estos portafolios óptimos forman lo que Markowitz llamó la *frontera eficiente*. Así, Markowitz (1952) propuso un modelo matemático para la **diversificación**.\n\n[^1]: Para analizar estas medidas de rentabilidad y riesgo, Markowitz propuso tomar como *proxies* de las mismas el rendimiento esperado y la varianza, respectivamente.\n\nSin embargo, Henry Markowitz sólo consideró activos riesgosos en su teoría. James Tobin (1958) amplió el trabajo de Markowitz al agregar un activo libre de riesgo al análisis, lo que llevó a que surgieran los conceptos de 'cartera súper eficiente' y la 'línea del mercado de capitales'. Debido a que están apalancadas, las carteras en la línea del mercado de capitales pueden superar a las carteras en la frontera eficiente (Glyn Horton, 2013). Por lo tanto, bajo la perspectiva de Tobin, los inversionistas deberían de diversificar su portafolio invirtiendo una proporción $w$ de su riqueza en un activo riesgoso y una proporción $1-w$ en activos libres de riesgo.\n\nEn este trabajo hacemos uso de los modelos Generales de Heterocedasticidad Condicional propuestos por Bollerslev (1986), para analizar a profundidad a varianza histórica del índice bursátil *Standard and Poor's 500* con el objetivo de encontrar los periodos de baja y alta volatilidad sostenida en los retornos del mismo. Así, con el conocimiento sobre el comportamiento de estos clusters de volatilidad, se propone un ejercicio teórico sobre las predicciones de volatilidad del modelo a la asignación de activos en un portafolio por medio de metas de volatilidad (Volatility Targeting), a la luz del teorema de separación de dos fondos de Tobin.\n\n## Desarrollo y Resultados\n\n### Preliminares: librerias usadas, datos y análisis de los retornos\n\n\n::: {.cell}\n\n:::\n\n\nVisualmente, se puede observar como la volatilidad de los retornos cambia en el tiempo. Se observa que los períodos de grandes retornos (positivos o negativos) tienden a ser seguidos de retornos grandes, mientras que los bajos retornos son seguidos de bajos retornos. Por lo que se pueden ver estos periodos de alta o baja volatilidad sostenida, conocidos como clusters de volatilidad.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cargar los datos\nsp500prices <- getSymbols(\"^GSPC\",auto.assign = FALSE, from = \"1989-01-03\", to = as.Date(\"2022-03-18\"))$'GSPC.Close'\ncolnames(sp500prices) <- 'SP500'\n\n# Calcular los retornos diarios\nsp500ret <- CalculateReturns(sp500prices)\nsp500ret <- sp500ret[-1,]\nlinea_cero <- sp500ret\nlinea_cero$cero <- 0\n\n\n# Graficar la serie de precios del SP500 y sus retornos\ngraf_retornos <- plot(sp500ret, main = \"Retornos diarios del S&P500\")\ngraf_retornos <- addSeries(linea_cero[, \"cero\"], col = \"red\", on = 1)\n\npar(mfrow = c(2,1))\nplot(sp500prices, main = \"Precios diarios del S&P500\")\ngraf_retornos\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/datos-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculando las volatilidades anualizadas en años cercanos a crisis económicas\nsd_anualizada <- \n  as.data.frame(cbind(\"2008\" = sqrt(252)*sd(sp500ret[\"2008\"]), \n        \"2009\" = sqrt(252)*sd(sp500ret[\"2009\"]), \n        \"2017\" = sqrt(252)*sd(sp500ret[\"2017\"]), \n        \"2018\" = sqrt(252)*sd(sp500ret[\"2018\"]), \n        \"2019\" = sqrt(252)*sd(sp500ret[\"2019\"]), \n        \"2020\" = sqrt(252)*sd(sp500ret[\"2020\"]), \n        \"2021\" = sqrt(252)*sd(sp500ret[\"2021\"]),\n        \"total\"= sqrt(252)*sd(sp500ret, na.rm = T)))\n\nkable(sd_anualizada, digits = 4, caption = \"Volatilidades Anualizadas en años cercanos a crisis económicas\", booktabs = T) %>% \n  kable_styling(full_width = T)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in kable_styling(., full_width = T): Please specify format in\nkable. kableExtra can customize either HTML or LaTeX outputs. See https://\nhaozhu233.github.io/kableExtra/ for details.\n```\n:::\n\n::: {.cell-output-display}\nTable: Volatilidades Anualizadas en años cercanos a crisis económicas\n\n|   2008|   2009|   2017|   2018|   2019|   2020|  2021|  total|\n|------:|------:|------:|------:|------:|------:|-----:|------:|\n| 0.4097| 0.2729| 0.0669| 0.1705| 0.1247| 0.3443| 0.131| 0.1798|\n:::\n:::\n\n\nLas fluctuaciones de la volatilidad en los diferentes períodos de tiempo se puede observar por medio de la volatilidad móvil de 1 y 3 meses:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,1))\n\n# Estimación móvil de 1 mes de la volatilidad anualizada\nchart.RollingPerformance(R = sp500ret[\"2000::2022\"], width = 22,\n                         FUN = \"sd.annualized\", scale = 252, main = \"Volatilidad móvil de 1 mes\")\n\n# Estimación móvil de 3 meses de la volatilidad anualizada\nchart.RollingPerformance(R = sp500ret[\"2000::2022\"], width = 3*22,\n                         FUN = \"sd.annualized\", scale = 252, main = \"Volatilidad móvil de 3 meses\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/Rolling volatility-1.png){width=672}\n:::\n:::\n\n\nComo se observa, la volatilidad de los retornos del S&P500 varía en el tiempo y puede depender de la varianza pasada, por lo que para estudiar su dinámica se necesita de un proceso que permita que la varianza condicional cambie en el tiempo como una función de errores pasados, a manera del modelo autorregresivo de heterocedasticidad condicional (ARCH) propuesto por Engle (1982), y la posterior generalización (GARCH) que permite una memoria más larga en el modelo y una estructura de rezagos más flexibles (Bollerslev, 1986).\n\nAl desarrollar modelos de heterocedasticidad condicional, se deben tener presentes las especificaciones para las ecuaciones de la media condicional, la varianza condicional y la distribución condicional del error.\n\n### Especificación de la varianza condicional y la distribución condicional del error\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Especificación de un modelo garch estándar\ngarchspec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),\n                        variance.model = list(model = \"sGARCH\"), \n                        distribution.model = \"norm\")\n\ngarchfit <- ugarchfit(data = sp500ret, spec = garchspec)\n\n# Obtener la volatilidad estimada \ngarchvol <- sigma(garchfit)\nplot(garchvol, main = \"Volatilidad estimada\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/modelo simple-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Calcular la volatilidad incondicional y los retornos estandarizados\nkable(sqrt(uncvariance(garchfit)), digits = 4, booktabs = T,\n      col.names =\"Volatilidad Incondicional de la inflación\")\n```\n\n::: {.cell-output-display}\n| Volatilidad Incondicional de la inflación|\n|-----------------------------------------:|\n|                                    0.0109|\n:::\n\n```{.r .cell-code}\nstdret <- residuals(garchfit, standardize = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Comparación visual de la distribución del error\nchart.Histogram(stdret, methods = c(\"add.normal\",\"add.density\"), \n                colorset = c(\"gray\",\"red\",\"blue\"), \n                main = \"Distribución de los retornos estandarizados vs la dist. normal\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nPor la presencia de eventos extremos la distribución empírica de los retornos tienen colas gruesas, por lo que el supuesto de normalidad puede ser inadecuado y puede que haya generado estimadores sesgados. Teniendo en cuenta que la distribución de los retornos estandarizados no siguen una distribución normal, pues presentan un exceso de curtosis, colas más gruesas y un efecto asimétrico, establecer una distribución t-Student con asimetría en lugar de una distribución normal para la especificación de la dsitribución condicional del error conduce a un modelo GARCH más realista.\n\nPor otro lado, cuando hay un efecto de apalantamiento las noticias negativas sobre rendimientos (choques negativos) afectan más a la varianza que las noticias positivas (choques positivos). Por el efecto asimétrico que presenta la distribución, se aplica un modelo gjr-GARCH para confirmar un posible efecto de apalantamiento. En este modelo se permite una respuesta asimétrica de la varianza a las noticias positivas y negativas al asignar más peso en las noticias negativas al tomar $(\\alpha + \\gamma)*\\varepsilon_t^2$ cuando $\\varepsilon_t \\le 0$ en lugar de solo $\\alpha*\\varepsilon_t^2$ cuando $\\varepsilon_t > 0$. La curva de impacto de noticias es una herramienta útil para visualizar la respuesta de la varianza a la sorpresa en los retornos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Especificación del gjr-GARCH\ngjrgarchspec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),\n                           variance.model = list(model = \"gjrGARCH\"),\n                           distribution.model = \"sstd\")\n\ngjrgarchfit <- ugarchfit(data = sp500ret, spec = gjrgarchspec)\n\n# Obtener la volatilidad estimada\ngjrgarchvol_mean <- fitted(gjrgarchfit)\ngjrgarchvol <- sigma(gjrgarchfit)\n \n# Comparar las volatilidades estimadas\nplotvol <- plot(abs(sp500ret), col = \"grey\", \n                main = \"Retornos y volatilidades estimadas\")\nplotvol <- addSeries(gjrgarchvol, col = \"red\", on=1)\nplotvol <- addSeries(garchvol, col = \"blue\", on=1)\nplotvol\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/gjr garch-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Curva de noticias\nplot(gjrgarchfit, which = 12)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nUn efecto apalancamiento asimétrico se puede ver en la figura anterior. A partir de la misma se concluye que la reacción de la varianza condicional es mayor ante choques negativos pasados que ante choques positivos pasados de la misma magnitud en los retornos del S&P500. Tanto así, que el mercado es relativamente insensible a los choques positivos en comparación con el aumento y la sensibilidad de la volatilidad que acompaña a los choques negativos con una mayor disminución en los precios.\n\n**Selección del modelo en base a los criterios de información**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# log-likelihood de los dos modelos\nlikelihood <- \n  data.frame(Garch = likelihood(garchfit), gjrGarch = likelihood(gjrgarchfit))\nrownames(likelihood) <- \"Log-Likelihood\"\n\n# Criterios de información\ncriterios_informacion <- \n  data.frame(Garch = infocriteria(garchfit), gjrGarch = infocriteria(gjrgarchfit))\n\ncolnames(criterios_informacion) <- c(\"Garch\", \"gjrGarch\")\n\nkable(rbind(criterios_informacion, likelihood), booktabs = T,\n      col.names = c(\"Garch\", \"gjrGarch\"),\n      digits = 4, format = \"latex\",\n      caption = \"Criterios de Información para los modelos de heterocedasticidad condicional\") %>% \n  kable_styling(full_width = T, latex_options = c(\"hold_position\"))\n```\n\n::: {.cell-output-display}\n\\begin{table}[!h]\n\n\\caption{\\label{tab:criterios de información}Criterios de Información para los modelos de heterocedasticidad condicional}\n\\centering\n\\begin{tabu} to \\linewidth {>{\\raggedright}X>{\\raggedleft}X>{\\raggedleft}X}\n\\toprule\n  & Garch & gjrGarch\\\\\n\\midrule\nAkaike & -6.5656 & -6.6531\\\\\nBayes & -6.5623 & -6.6472\\\\\nShibata & -6.5656 & -6.6531\\\\\nHannan-Quinn & -6.5645 & -6.6511\\\\\nLog-Likelihood & 27471.3350 & 27840.3342\\\\\n\\bottomrule\n\\end{tabu}\n\\end{table}\n:::\n:::\n\n\nCon base en los criterios de información, se concluye que el modelo gjr-GARCH con distribución t-Student es un modelo más adecuado y realista que un modelo simple con distribución normal.\n\n### El modelo en media\n\nModelar la dinámica de la media condicional generalmente tiene un efecto importante en los rendimientos estimados, pero sólo un efecto pequeño en las predicciones de volatilidad. La teoría de econometría financiera sugiere que el efecto puede ser tan mínimo, que si el interés está solo en la dinámica de la volatilidad, generalmente se puede ignorar la dinámica de la media y asumir una especificación simple de media constante para guardar parsimonia. Para confirmar que este es el caso, consideraremos un modelo AR(1) y un modelo GARCH en media para ver cómo se relacionan las volatilidades.\n\nEn el modelo AR(1), el signo del parámetro autorregresivo depende de la reacción del mercado a las noticias $\\mu_t = \\mu + \\rho(R_{t-1} - \\mu)$. Un valor positivo de $\\rho$ es consistente con la interpretación de que los mercados reaccionan de manera subestimada a las noticias, lo que conduce a un momentum en los rendimientos (los rendimientos superiores al promedio son seguidos por rendimientos superiores al promedio). Un valor negativo de $\\rho$ es coherente con la interpretación de que los mercados reaccionan de forma exagerada a las noticias, lo que conduce a una reversión de la rentabilidad (las rentabilidades superiores a la media van seguidas de rentabilidades inferiores a la media). En todo caso, si $|\\rho|<1$, entonces las desviaciones de los retornos de su media de largo plazo ($\\mu$) son transitorias.\n\nPor lo que surge la pregunta: ¿Los rendimientos diarios del S&P500 se caracterizan por un momentum o un efecto de reversión en su dinámica AR(1)?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Especificación AR(1) de un GARCH asimétrico\nargarchspec <- ugarchspec(mean.model = list(armaOrder = c(1,0)),\n                        variance.model = list(model = \"gjrGARCH\"),\n                        distribution.model = \"sstd\")\n\nargarchfit <- ugarchfit(data =  sp500ret, spec = garchspec)\n\n# Coeficientes del modelo de la media\nkable(coef(argarchfit)[c(1:2)], digits = 6, booktabs = T, format.args = list(scientific = FALSE), col.names =\"Coeficientes del modelo GARCH con una especificación AR(1) en la media condicional\")\n```\n\n::: {.cell-output-display}\n|      | Coeficientes del modelo GARCH con una especificación AR(1) en la media condicional|\n|:-----|----------------------------------------------------------------------------------:|\n|mu    |                                                                           0.000642|\n|omega |                                                                           0.000002|\n:::\n\n```{.r .cell-code}\n# Media y volatilidad del modelo AR(1)\nar1_mean <- fitted(argarchfit)\nar1_vol <- sigma(argarchfit)\n```\n:::\n\n\nDado que el coeficiente AR(1) en el modelo medio es negativo, encontramos un efecto de reversión en términos de rendimiento predicho. Después de una rentabilidad superior a la media, esperamos una rentabilidad inferior a la media. Y después de una rentabilidad inferior a la media, esperamos una rentabilidad superior a la media. También, como este coeficiente es cercano a cero, las desviaciones de los retornos diarios son transitorias.\n\nEn contraste con el uso de un modelo ARMA para la media, tenemos que un modelo GARCH en media no hace uso de la autocorrelación de los rendimientos. Sino que explota la relación entre el rendimiento esperado y la varianza del rendimiento. Cuanto mayor sea el riesgo en términos de varianza, mayor debería ser el rendimiento esperado de la inversión. Por lo que es un modelo que cuantifica el intercambio entre riesgo y recompensa.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Especificación de un GARCH en media\ngim_garchspec <- ugarchspec( \n  mean.model = list(armaOrder = c(0,0), archm = TRUE, archpow = 2),\n  variance.model = list(model = \"gjrGARCH\"), \n  distribution.model = \"sstd\")\n\ngim_garchfit <- ugarchfit(data = sp500ret , spec = gim_garchspec)\n\n# Media y volatilidad del modelo AR(1)\ngim_mean <- fitted(gim_garchfit)\ngim_vol <- sigma(gim_garchfit)\n\n# Correlación entre los retornos estimados del modelo AR(1) y el modelo en media\nkable(cor(ar1_mean, gim_mean), \n      col.names = \"Correlación entre los retornos estimados del modelo Garch-AR(1) y el modelo Garch en media\", format = \"latex\", digits = 4, booktabs = T) %>%\n  kable_styling(full_width = T)\n```\n\n::: {.cell-output-display}\n\\begin{tabu} to \\linewidth {>{\\raggedleft}X}\n\\toprule\nCorrelación entre los retornos estimados del modelo Garch-AR(1) y el modelo Garch en media\\\\\n\\midrule\n0.4406\\\\\n\\bottomrule\n\\end{tabu}\n:::\n\n```{.r .cell-code}\n# Correlación entre los retornos estimados de los modelos en media\ncorrelacion_modelos <- as.data.frame(cor(merge(gjrgarchvol, ar1_vol, gim_vol)))\nrownames(correlacion_modelos) <- c(\"gjrGarch\", \"AR(1)\", \"Garch en media\")\ncolnames(correlacion_modelos) <- c(\"gjrGarch\", \"AR(1)\", \"Garch en media\")\n\nkable(correlacion_modelos, booktabs = T,\n      digits = 4, format = \"latex\",\n      caption = \"Correlación entre las volatilidades estimadas para diferentes especificaciones de modelos Garch\") %>% \n  kable_styling(full_width = T)\n```\n\n::: {.cell-output-display}\n\\begin{table}\n\n\\caption{\\label{tab:garch in mean}Correlación entre las volatilidades estimadas para diferentes especificaciones de modelos Garch}\n\\centering\n\\begin{tabu} to \\linewidth {>{\\raggedright}X>{\\raggedleft}X>{\\raggedleft}X>{\\raggedleft}X}\n\\toprule\n  & gjrGarch & AR(1) & Garch en media\\\\\n\\midrule\ngjrGarch & 1.0000 & 0.9678 & 0.9993\\\\\nAR(1) & 0.9678 & 1.0000 & 0.9696\\\\\nGarch en media & 0.9993 & 0.9696 & 1.0000\\\\\n\\bottomrule\n\\end{tabu}\n\\end{table}\n:::\n:::\n\n\nExiste un gran desacuerdo entre los rendimientos pronosticados obtenidos con los modelos Garch-AR(1) y GARCH en media, como lo demuestra la baja correlación. Debido a que el rendimiento medio es cercano a cero para los rendimientos diarios, estas diferencias en la predicción de la media tienen poco impacto en las predicciones de volatilidad. Su correlación es casi uno. Como sólo nos interesa la dinámica de la volatilidad, y para guardar parsimonia, estimaremos modelos GARCH con media constante.\n\n### Extensión del análisis de la dinámica de la volatilidad de los retornos del SP500\n\nEn las gráficas pasadas se observó cómo la volatilidad de la rentabilidad financiera se agrupa a lo largo del tiempo: los periodos de volatilidad superior a la media van seguidos de periodos de volatilidad inferior a la media. En el largo plazo, se espera que:\n\n-   Cuando la volatilidad es alta, la misma disminuirá y volverá a su promedio a largo plazo.\n-   Cuando la volatilidad es baja, la misma aumentará y volverá a su promedio a largo plazo.\n\nEn la estimación de los modelos GARCH podemos explotar este comportamiento de reversión a la media de la volatilidad mediante 'volatility targeting' y confirmar que la volatilidad a largo plazo implícita en el modelo GARCH sea igual a la desviación estándar de la muestra.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Especificación para variance targeting\ntargarchspec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),\n                        variance.model = list(model = \"gjrGARCH\",\n                                              variance.targeting = TRUE),\n                        distribution.model = \"sstd\")\n\ntargarchfit <- ugarchfit(data = sp500ret, spec = targarchspec)\n\ntargarchvol <- sigma(targarchfit)\n\n# Comparar contra gjrGarch\n\n# log-likelihood de los dos modelos\nlikelihood_2 <- \n  data.frame(gjrGarch = likelihood(gjrgarchfit), tarGarch = likelihood(targarchfit))\nrownames(likelihood_2) <- \"Log-Likelihood\"\n\n# Criterios de información\ncriterios_informacion_2 <- \n  data.frame(gjrGarch = infocriteria(gjrgarchfit), tarGarch = infocriteria(targarchfit))\n\ncolnames(criterios_informacion_2) <- c(\"gjrGarch\", \"tarGarch\")\n\nkable(rbind(criterios_informacion_2, likelihood_2), booktabs = T,\n      col.names = c(\"gjrGarch\", \"Volatility targeting gjrGarch\"),\n      digits = 4, format = \"latex\",\n      caption = \"Criterios de Información para los modelos GARCH con objetivo de volatilidad\") %>% \n  kable_styling(full_width = T, latex_options = c(\"hold_position\"))\n```\n\n::: {.cell-output-display}\n\\begin{table}[!h]\n\n\\caption{\\label{tab:unnamed-chunk-6}Criterios de Información para los modelos GARCH con objetivo de volatilidad}\n\\centering\n\\begin{tabu} to \\linewidth {>{\\raggedright}X>{\\raggedleft}X>{\\raggedleft}X}\n\\toprule\n  & gjrGarch & Volatility targeting gjrGarch\\\\\n\\midrule\nAkaike & -6.6531 & -6.6532\\\\\nBayes & -6.6472 & -6.6482\\\\\nShibata & -6.6531 & -6.6532\\\\\nHannan-Quinn & -6.6511 & -6.6515\\\\\nLog-Likelihood & 27840.3342 & 27839.8445\\\\\n\\bottomrule\n\\end{tabu}\n\\end{table}\n:::\n\n```{.r .cell-code}\n# Volatilidad implícita de largo plazo\nkable(data.frame(Garch = sqrt(uncvariance(garchfit)), \n                 tarGarch = sqrt(uncvariance(targarchfit))), \n      col.names = c(\"Modelo Garch simple\", \"Modelo gjrGarch con volatility targeting\"), \n      format = \"latex\", digits = 4, booktabs = T,\n      caption = \"Volatilidad implícita de largo plazo\") %>%\n  kable_styling(full_width = T, latex_options = c(\"hold_position\"))\n```\n\n::: {.cell-output-display}\n\\begin{table}[!h]\n\n\\caption{\\label{tab:unnamed-chunk-6}Volatilidad implícita de largo plazo}\n\\centering\n\\begin{tabu} to \\linewidth {>{\\raggedleft}X>{\\raggedleft}X}\n\\toprule\nModelo Garch simple & Modelo gjrGarch con volatility targeting\\\\\n\\midrule\n0.0109 & 0.0113\\\\\n\\bottomrule\n\\end{tabu}\n\\end{table}\n:::\n\n```{.r .cell-code}\n# all.equal(sqrt(uncvariance(gjrgarchfit)), sd(sp500ret), tol = 1e-3)\n# all.equal(sqrt(uncvariance(targarchfit)), sd(sp500ret), tol = 1e-3)\n```\n:::\n\n\nLos modelos que se han estudiado hasta ahora conducen a una estimación de la volatilidad dentro de muestra obtenida al estimar el modelo GARCH solo una vez y utilizando la serie de tiempo completa, lo cual puede causar sesgo (look-ahead bias o sesgo de anticipación). Sin embargo, en los modelos de ventanas móviles se evitan estos sesgos al condicionar la estimación a usar sólo los rendimientos disponibles en el momento anterior de la estimación. Es decir, se volvería a estimar el modelo en cada ventana utilizando sólo los rendimientos que son realmente observables en el momento de la estimación.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Especificación para garch en ventanas móviles\nrollgarchspec <- ugarchspec(mean.model = list(armaOrder = c(0,0)),\n                        variance.model = list(model = \"gjrGARCH\",\n                                              variance.targeting = TRUE),\n                        distribution.model = \"sstd\")\n\nrollgarchfit <- ugarchroll(garchspec, \n                           data = sp500ret,\n                           n.start = 2000, refit.window = \"moving\",  refit.every = 500)\n\n# Predicciones móviles\npreds <- as.data.frame(rollgarchfit)\n\n# Comparación de la volatilidad estimada en el modelo dentro de muestra y el modelo móvil\ngarchvolroll <- xts(preds$Sigma, order.by = as.Date(rownames(preds)))\nvolplot <- plot(gjrgarchvol, col = \"darkgrey\", lwd = 1.5, \n                main = \"Pronósticos de volatilidad dentro de muestra y por ventanas móviles\")\nvolplot <- addSeries(garchvolroll, col = \"blue\", on = 1)\nplot(volplot)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n**Asignación táctica de activos por medio de Volatilidad Objetivo**\n\nLas predicciones de volatilidad de GARCH tienen un uso práctico directo en la asignación de carteras. De acuerdo con el teorema de separación de dos fondos de James Tobin, debe invertir una proporción w de su riqueza en un portafolio riesgoso y el resto en un activo libre de riesgo, como una letra del Tesoro de los Estados Unidos. Si se tiene como objetivo una cartera con una volatilidad anualizada del 5%, y la volatilidad anualizada del activo de riesgo es w, entonces se debe invertir (0.05/w) en el activo de riesgo, en este caso, el S&P500.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Volatilidad anualizada a partir del modelo gjrGARCH de ventanas móviles con \n# distribución t-Student asimétrica\nvolatilidad_anualizada_estimada <- sqrt(252)*garchvolroll\n\n# Calcular los pesos asignados al activo riesgoso con una volatilidad objetivode 5% anual \npesos_de_asignacion <- 0.05 / volatilidad_anualizada_estimada\n\n# Comparar la volatilidad anualizada con los pesos del portafolio\nplot(merge(volatilidad_anualizada_estimada, pesos_de_asignacion), multi.panel = TRUE,\n     main = \"Vol. anualizada y pesos de asignación del activo riesgoso\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nEn el gráfico anterior es fácil observar la dinámica en la asignación de los activos dentro de un portafolio. En nuestra cartera compuesta por las letras del tesoro de Estados Unidos y el S&P500, como las letras del tesoro son libres de riesgo, la pregunta que nos surge es qué peso se le debe asignar al S&P500 dentro del portafolio teniendo en cuenta la restricción de exposición al riesgo que nos imponemos. Para marzo del 2022, el modelo recomienda un portafolio con una exposición de aproximadamente un 20% al S&P500 y un 80% en activos libre de riesgo con una volatilidad objetivo del 5%.\n\n**Breve aplicación de un VaR - Valor en Riesgo**\n\nLos gráficos de valor en riesgo muestran una variación temporal sustancial en el riesgo a la baja. Esta variación temporal se debe principalmente a la variación temporal de la volatilidad.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 5% Valor en Riesgo \ngarchVaR <- quantile(rollgarchfit, probs = 0.05)\n\n# Volatilidad para el Valor en Riesgo\ngarchvolroll_var <- xts(preds$Sigma, order.by = time(garchVaR))\n\n# Análisis visual de los comovimientos\ngarchplot <- plot(garchvolroll_var, ylim = c(-0.1, 0.1), \n     main = \"Volatilidad diaria y el 5% VaR\")\ngarchplot <- addSeries(garchVaR, on = 1, col = \"blue\")\nplot(garchplot, \n     main = \"Volatilidad diaria y el 5% VaR\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nEs notorio el alto comovimiento entre las dos series. La intuición es que, si la volatilidad se dispara, se corre el riesgo de perder más dinero. Por eso que también el valor en riesgo se vuelve más extremo. En marzo 2022, el valor en riesgo de este portafolio es de 1.95%, o de casi 20 dólares por cada 1000 invertido en el activo riesgoso.\n\nUsando los pesos asignados en el ejercicio anterior, si se fuera a invertir \\$100,000 dólares hoy: \\$20,000 serían invertidos en el S&P500 y \\$80,000 dólares en las letras del tesoro de Estados Unidos. En su conjunto, el portafolio tendría un Valor en Riesgo de \\$390.5 dólares. Un monto expuesto al riesgo de sólo 0.391% del capital invertido.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}